\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{graphicx}
\usepackage{amsmath, amssymb}
\usepackage{mathtools} % for \xmapsto
\usepackage{bm}
\usepackage[most]{tcolorbox}
\usepackage{tabularx}
\usepackage{pifont} % optional for symbols
% --- Flowcharts (TikZ) ---
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,shapes.geometric,fit,calc}
\usepackage{xcolor}
% Algorithms (compact)
\usepackage{algorithm}
\usepackage{algpseudocode}

% Optional: slightly tighter algorithm typography
\algrenewcommand\algorithmicrequire{\textbf{Input:}}
\algrenewcommand\algorithmicensure{\textbf{Output:}}
\algrenewcommand\algorithmiccomment[1]{\hfill{\footnotesize$\triangleright$~#1}}

\usepackage{hyperref}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{booktabs,longtable,array,makecell}
\setlength{\LTleft}{0pt}   % no left indent for longtable
\setlength{\LTright}{0pt}  % no right indent for longtable
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}


% --- Theorems, lemmas, claims, proofs ---
\usepackage{amsthm}

\theoremstyle{plain} % bold headings, italic body
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{claim}[theorem]{Claim}

\theoremstyle{definition} % bold heading, upright body
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark} % italic heading, upright body
\newtheorem{remark}[theorem]{Remark}
\newtheorem{note}[theorem]{Note}

% Optional: unnumbered versions
\newtheorem*{theorem*}{Theorem}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{claim*}{Claim}

% Proof environment is provided by amsthm:
% \begin{proof} ... \end{proof}
% Customize QED symbol if you like:
\renewcommand{\qedsymbol}{$\blacksquare$}

\newcommand{\code}[1]{\texttt{#1}}

\definecolor{prefillcolor}{RGB}{173,216,230}  % Light blue
\definecolor{decodecolor}{RGB}{144,238,144}   % Light green
\definecolor{gridcolor}{RGB}{200,200,200}     % Light gray
\definecolor{highlightcolor}{RGB}{255,182,193} % Light pink for integration region


% (Optional) If you want equations numbered by section (since you already use amsmath):
\numberwithin{equation}{section}



\title{BLIS: Blackbox Inference Performance Estimator}
\author{AI Platform Optimization Team}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This paper introduces BLIS, a system for blackbox inference performance estimation 
designed to model inference request flows and latency.
\end{abstract}

\section{Introduction}
\label{sec:introduction}

\section{Related Work}
\label{sec:related-work}

\section{Design overview}
\label{sec:design-overview}

BLIS is primarily geared towards vLLM; we discuss extensions 
to other inference platforms (e.g., sglang) in future work.

\subsection{vLLM overview}
\label{subsec:vllm-overview}
We will focus on handling of an inference request by vLLM. vLLM
has two main components: the API server and the engine core; these operate as separate threads and
communicate through a message queue.

\subsubsection{API server thread}
The API server is implemented using FastAPI. Its role is to handle client-facing tasks without blocking on actual model execution.
The API thread is responsible for:
\begin{enumerate}
    \item Receiving and tokenizing incoming requests from clients.
    \item Enqueuing tokenized requests into the message queue.
    \item Streaming back partial responses as they become available from the engine.
    \item Detokenizing completed sequences and packaging them into response
          objects.
    \item Emitting the final response back to the client.
\end{enumerate}

\subsubsection{Engine core thread}
The engine core runs the central \emph{inference loop}. This loop is driven by a
scheduler that repeatedly:
\begin{enumerate}
    \item Collects pending requests from the queue, forming a dynamic batch.
    \item Determines whether a request is in a \emph{prefill} (first token)
          or \emph{decode} (subsequent tokens) phase.
    \item Executes the forward pass on the GPU for that batch.
    \item Updates KV cache blocks, manages allocation and eviction, and applies
          prefix caching optimizations when possible.
    \item Returns generated tokens back to the API layer, either for streaming
          or final response.
\end{enumerate}
We will refer to this engine loop as the \emph{busy loop} since it continuously
steps through request-batches at a fine-grained timescale.

\subsection{Design of BLIS}
\label{subsec:blis-design}

\section{Latency model}
\label{sec:latency-model}

\subsection{Request types}
\label{subsubsec:request-types}

Requests can be of two types: \textit{prefill-only} or \textit{decode}. 
Prefill-only requests have their maximum output length set to $1$, and \textit{decode}
requests have this set to a number greater than $1$.

\subsection{Request life-cycle}
\label{subsubsec:request-life-cycle}

\begin{figure}[!ht]
  \centering
  \includegraphics[height=0.8\textwidth]{figs/reqlifecycle.png}
  \caption{Request Lifecycle}
  \label{fig:req-lifecycle}
\end{figure}

The life of an inference request in the system passes through multiple stages 
as  illustrated in Figure \ref{fig:req-lifecycle} and described below.

\paragraph*{1. Ingress.}
The client emits an inference request $i$ to the server. This contributes 
a network latency that depends linearly on the number of input tokens 
$\ell_i^{\text{in}}$.

\paragraph*{2. Pre-process.}
Upon arrival, the API server tokenizes the prompt, performs light
validation, and enqueues the request into the message queue. This contributes 
a latency that depends linearly on $\ell_i^{\text{in}}$.

\paragraph*{3. Scheduling.} The request waits in the queue until there is 
sufficient GPU capacity. During this waiting period, other requests get to participate
in the busy loop iterations.

\paragraph*{4. Chunked prefill.} The uncached portion of this request is 
prefilled one chunk at a time. The latency of this stage equals the sum of the 
duration of the busy loop iterations in which this request prefills.

\paragraph*{5. Decode.} The latency of this stage equals the sum of the duration
of the busy loop iterations in which this request is in its decode phase. 
The first output token is generated during the prefill phase, and subsequent 
tokens are generated in the decode iterations.

\paragraph*{6. Post-process.} Once all output tokens are produced, 
the API server detokenizes them and
packages the final response. The latency of this stage depends linearly on the 
number of output tokens $\ell_i^{\text{out}}$.

\paragraph*{7. Egress.}
The server emits response $i$ to the
client. This contributes a network latency that depends linearly 
on the number of output tokens $\ell_i^{\text{out}}$.


\section{Trace-Only Estimation of Step-Level Execution Coefficients}
\label{sec:step_beta_estimation}

This section develops a trace-only methodology for estimating the
\emph{step-level} execution coefficients of a vLLM-style inference engine.
Our goal is to recover the coefficient vector
$\beta=(\beta_0,\beta_1,\beta_2)$ in a step-time model that is used by the
simulator, using only production traces that report phase start/end times and
aggregate token counts.
No step boundaries, per-step timings, or engine instrumentation are assumed.

We present two estimators.
Section~\ref{sec:baseline} introduces a simple, trace-only baseline that fits
phase durations using time-integrated workload signals.
Section~\ref{sec:em_estimation} then refines this baseline by making the
\emph{latent placement of steps in wall-clock time} explicit and estimating it
via an EM procedure with exact handling of the final partial prefill chunk.
The baseline can be interpreted as a one-shot instance of the same latent-step
allocation view, with a phase-local uniform allocation surrogate; EM replaces
this surrogate by an iteration-dependent allocation driven by a learned
step-density model.

\paragraph{Notation and units (summary).}
Table~\ref{tab:notation_summary} lists the principal symbols used in the baseline
and EM estimators and their units.

\begin{table}[ht!]
\centering
\small
\begin{tabular}{lll}
\toprule
\textbf{Symbol} & \textbf{Units} & \textbf{Meaning} \\
\midrule
$k$ & step index & busy-loop iteration (latent execution step) \\
$r$ & request index & inference request; each has one prefill phase and one decode phase \\
$i$ & phase index & a phase instance (prefill or decode) of a specific request \\
$j$ & grid index & index of a trace-induced time-grid cell $[g_j,g_{j+1})$ \\
$m$ & iteration index & EM iteration index \\[0.5ex]

$t_{i,s},\,t_{i,e}$ & seconds & start and end times of phase instance $i$ \\
$\ell_i$ & seconds & observed duration of phase instance $i$ ($\ell_i=t_{i,e}-t_{i,s}$) \\
$\tau_i$ & categorical & phase type of instance $i$ (\textsf{prefill} or \textsf{decode}) \\
$N_i$ & steps & trace-inferred step count for phase instance $i$ (fixed) \\[0.5ex]

$C$ & tokens/step & prefill chunk size \\
$P_r$ & tokens & total (uncached) prefill tokens for request $r$ \\
$D_r$ & tokens & total decode tokens for request $r$ \\
$\rho_r$ & tokens & tokens in the final prefill step of request $r$, Eq.~\eqref{eq:rho_def} \\
$\mu_r$ & tokens & missing token mass in final prefill step ($\mu_r=C-\rho_r$) \\[0.5ex]

$a_r(t)$ & unitless & indicator that request $r$ is in prefill at time $t$ (trace-visible) \\
$p^{\mathrm{pf}}_{\mathrm{full}}(t)$ & tokens/step & naive full-chunk prefill pressure $C\sum_r a_r(t)$ \\
$p^{\mathrm{dec}}(t)$ & tokens/step & decode pressure from overlapping decode phases \\[0.5ex]

$\widehat\lambda_i$ & steps/sec & baseline phase-local step-density proxy $N_i/\ell_i$, Eq.~\eqref{eq:baseline_lambda_hat} \\
$c(t)$ & tokens/sec & baseline partial-chunk correction signal (none/uniform/end) \\[0.5ex]

$A_i^{\mathrm{pf}}$ & tokens & baseline prefill exposure (feature), Eq.~\eqref{eq:baseline_integrated_exposures_pf} \\
$A_i^{\mathrm{dec}}$ & tokens & baseline decode exposure (feature), Eq.~\eqref{eq:baseline_integrated_exposures_dec} \\[0.5ex]

$g_1<\cdots<g_{J+1}$ & seconds & trace-induced grid boundaries; cells are $[g_j,g_{j+1})$ \\
$\mathcal{J}(i)$ & set & grid cells fully contained in phase window of $i$ (EM) \\[0.5ex]

$Z_{ij}$ & steps & latent number of steps of phase $i$ executed in grid cell $j$ (EM) \\
$\pi^{(m)}_{ij}$ & unitless & EM allocation weight of phase $i$ to cell $j$ at iter.~$m$, Eq.~\eqref{eq:em_pi} \\
$\Delta^{(m)}_j$ & sec/step & EM cell-level step-time proxy at iter.~$m$, Eq.~\eqref{eq:em_step_rate} \\
$\lambda^{(m)}_j$ & steps/sec & EM cell-level step density $1/\Delta^{(m)}_j$, Eq.~\eqref{eq:em_step_rate} \\
$\tilde p^{\mathrm{pf},(m)}_j$ & tokens/step & EM effective prefill pressure on cell $j$ at iter.~$m$ \\[0.5ex]

$\beta_0$ & sec/step & fixed per-step overhead coefficient \\
$\beta_1,\beta_2$ & sec/token & per-token execution costs (prefill / decode) \\
$\beta^{(m)}$ & mixed & coefficient vector at EM iteration $m$ \\
\bottomrule
\end{tabular}
\caption{Notation and units used in trace-only step-level coefficient estimation (baseline and EM).}
\label{tab:notation_summary}
\end{table}


% ============================================================
\subsection{Problem Setup and Step-Level Model}
\label{sec:problem_setup}

We consider a vLLM-style inference engine that advances execution through a
single logical busy-loop.
Each busy-loop iteration (a \emph{step}) executes one forward-pass cycle that
may process prefill tokens, decode tokens, or both, for a set of concurrently
active requests.
Steps are assumed to execute sequentially.

Let $k$ index busy-loop steps.
We model the duration of step $k$ as
\begin{equation}
\Delta t_k
=
\beta_0
+
\beta_1\,T^{\mathrm{pf}}_k
+
\beta_2\,T^{\mathrm{dec}}_k,
\label{eq:step_model}
\end{equation}
where $\beta_0\ge 0$ is a fixed per-step overhead (seconds/step),
$\beta_1,\beta_2\ge 0$ are per-token costs (seconds/token), and
$T^{\mathrm{pf}}_k$ and $T^{\mathrm{dec}}_k$ are the total numbers of prefill and
decode tokens processed in step $k$ across all requests.

This affine step-time model is the fundamental abstraction used by our
simulator. Accurate simulation therefore requires identifying $\beta$ from
trace-only data.

\paragraph{What traces provide.}
Production inference traces do not expose step boundaries or per-step execution
timings.
Instead, they provide a collection of \emph{phase instances}, indexed by $i$,
each corresponding to either the prefill phase or the decode phase of a single
request.
For each phase instance $i$, the trace provides:
(i) the request id $r_i$,
(ii) the phase type $\tau_i\in\{\textsf{prefill},\textsf{decode}\}$,
(iii) start and end times $(t_{i,s},t_{i,e})$ and duration
$\ell_i=t_{i,e}-t_{i,s}$, and
(iv) aggregate token counts for that request, including total prefill tokens
$P_{r_i}$ and total decode tokens $D_{r_i}$.
Since each phase instance uniquely identifies its request, we write $P_r$ and
$D_r$ without ambiguity.

From these fields, we derive a trace-inferred step count $N_i\in\mathbb{N}$ for
each phase instance.
For a decode phase, execution proceeds one token per step, so $N_i=D_r$.
For a prefill phase, execution is chunked: under prefill chunk size $C$, a
standard trace-inferred choice is
$N_i=\lceil P_r/C\rceil$.\footnote{
Prefix-cached tokens do not contribute to execution steps and are therefore
excluded from $P_r$. This treatment is consistent with the execution semantics
of vLLM-style inference engines.
}

\paragraph{Latent step allocation viewpoint (common to baseline and EM).}
The central obstacle in trace-only estimation is that, although each phase
instance $i$ has a known total step count $N_i$, the trace does not reveal
\emph{when within} $[t_{i,s},t_{i,e})$ those $N_i$ steps occurred, nor how the
per-step token totals $(T^{\mathrm{pf}}_k,T^{\mathrm{dec}}_k)$ varied across
time.
Both the baseline and EM estimators operate by constructing
\emph{trace-only attribution models} that allocate this latent step exposure
over wall-clock time using only trace-visible phase boundaries.
These attribution models are not claims about true step boundaries; they are
used only through time integrals on a grid induced by the trace.


% ============================================================
\subsection{Trace-Derived Token Pressures}
\label{sec:pressures}

\paragraph{Intuition.}
Inference executes as a sequence of discrete steps, but traces provide only
coarse phase-level summaries.
The goal is not to reconstruct the hidden step schedule; rather, we seek
step-level coefficients that explain how prefill and decode work contribute to
elapsed time \emph{when aggregated over many steps}.
We therefore represent step-level workload using \emph{token pressures}:
trace-derived functions of wall-clock time that quantify, in units of
tokens/step, how much prefill and decode work would be attributed to a
representative busy-loop step executed at that time.
These pressures depend only on phase overlap in wall-clock time and can be
computed exactly from phase boundaries.
Figure~\ref{fig:overlap_phases} illustrates the resulting overlap structure.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=\linewidth]{figs/overlap_phases.pdf}
  \caption{\textbf{Phase overlap and inferred workload over wall-clock time.}
Each horizontal bar represents a trace-visible prefill or decode phase of a
request, while dashed vertical lines indicate wall-clock instants at which a
step boundary may occur. Although traces expose only phase start/end times—not
step boundaries—the degree of phase overlap determines how much work is executed
per step when time is aggregated. The estimators below convert overlap in
wall-clock time into token exposures consistent with the step-level model.}
\label{fig:overlap_phases}
\end{figure}

\paragraph{Trace-induced time grid.}
Let $\{[g_j,g_{j+1})\}_{j=1}^J$ denote the piecewise-constant time grid formed by
the union of all trace phase boundaries.
All pressures and correction signals introduced below are constant on each grid
cell, and all estimation procedures use them only through integrals over phase
windows.

\paragraph{Terminology: instantaneous quantities and exposures.}
We distinguish between \emph{instantaneous} quantities, defined as functions of
wall-clock time $t$ on the trace-induced grid, and \emph{exposures}, which are
obtained by integrating instantaneous quantities over a phase window and serve
as regression features.
Instantaneous \emph{pressures} quantify work performed per execution step
(tokens/step).
Exposures are phase-level scalars with units of tokens, obtained either by
(i) converting time-integrated pressures using a step-density surrogate
(baseline), or (ii) forming step-averaged pressures via a step-allocation model
and aggregating over a fixed step count (EM).

\paragraph{Instantaneous token pressures.}
We define two trace-derived, piecewise-constant pressures (tokens/step).
The decode pressure $p^{\mathrm{dec}}(t)$ is the total decode-token work that
would be attributed to a representative busy-loop step executed at time $t$,
given the set of requests whose trace-visible decode phases overlap $t$.
For prefill, we start from the \emph{naive full-chunk} pressure
\begin{equation}
p^{\mathrm{pf}}_{\mathrm{full}}(t)=C\sum_r a_r(t),
\label{eq:pf_full_pressure}
\end{equation}
where $a_r(t)\in\{0,1\}$ indicates whether request $r$ is in its prefill phase at
time $t$.
This full-chunk pressure treats each active prefill request as contributing $C$
tokens per step.
Accounting for the final partial prefill chunk is handled separately:
the baseline introduces a correction in \emph{exposure space} via a
time-based signal $c(t)$, whereas EM incorporates the correction directly in
\emph{step space} by modifying an iteration-dependent effective prefill pressure
on the trace grid.


\subsubsection{Prefill Chunking and Partial-Chunk Correction Signals}
\label{sec:prefill_correction}

Decode contributes exactly one token per active request per step.
Prefill, however, proceeds in chunks of size $C$ tokens per step, except for the
final prefill step of a request, which may process fewer than $C$ tokens.
Naively treating all prefill steps as full chunks introduces systematic bias.

For a request $r$ with $P_r$ prefill tokens and $N_r$ prefill steps, the final
prefill step processes
\begin{equation}
\rho_r = P_r - C\,(N_r-1),
\qquad \rho_r \in (0,C],
\label{eq:rho_def}
\end{equation}
and the missing token mass relative to a full chunk is
\[
\mu_r = C - \rho_r \in [0,C).
\]

\paragraph{No partial-chunk correction (baseline ablation).}
The simplest baseline ignores partial chunks and uses
$p^{\mathrm{pf}}_{\mathrm{full}}(t)$ as the effective prefill pressure. This
serves as a natural ablation: it is fully trace-only and makes no assumptions
about where the final prefill step occurs within a prefill interval.

\paragraph{Uniform redistribution correction (implemented in integrated form).}
A more refined baseline accounts for $\mu_r$ by redistributing it uniformly over
the prefill interval of request $r$.
Let $[t_{r,s},t_{r,e})$ denote the trace-visible prefill interval of request $r$.
Define a per-request correction signal (tokens/second)
\begin{equation}
c_r^{\mathrm{uni}}(t)
=
\frac{\mu_r}{t_{r,e}-t_{r,s}}\,
\mathbf{1}\{t\in[t_{r,s},t_{r,e})\},
\qquad
\text{units: tokens/second},
\label{eq:uniform_corr_signal}
\end{equation}
and the aggregate correction signal
\begin{equation}
c^{\mathrm{uni}}(t)=\sum_r c_r^{\mathrm{uni}}(t).
\label{eq:uniform_corr_signal_sum}
\end{equation}
By construction,
$\int_{t_{r,s}}^{t_{r,e}} c_r^{\mathrm{uni}}(t)\,dt=\mu_r$, so total missing mass
is preserved exactly when integrating over time.

\paragraph{End-localized correction (implemented on the trace grid).}
Uniform redistribution implicitly treats the final prefill step as equally
likely to occur anywhere within the prefill interval.
An alternative trace-only assumption is that the final prefill step completes
near the trace-visible end time $t_{r,e}$.
Let $j(r)$ be the index of the unique trace-grid cell containing $t_{r,e}$ under
the half-open convention (with boundary clamping at the end).
Define the per-request end-localized correction signal (tokens/second)
\begin{equation}
c_r^{\mathrm{end}}(t)
=
\frac{\mu_r}{g_{j(r)+1}-g_{j(r)}}\,
\mathbf{1}\{t\in[g_{j(r)},g_{j(r)+1})\},
\qquad
\text{units: tokens/second},
\label{eq:end_corr_signal}
\end{equation}
and the aggregate correction signal
\begin{equation}
c^{\mathrm{end}}(t)=\sum_r c_r^{\mathrm{end}}(t).
\label{eq:end_corr_signal_sum}
\end{equation}
Again, $\int c_r^{\mathrm{end}}(t)\,dt=\mu_r$ by construction.

\paragraph{Remark (why correction signals appear in the baseline).}
In the baseline, pressures are represented in units of tokens/step and enter the
estimator only through time integrals that are converted into token totals using
a phase-local step-density proxy (Section~\ref{sec:baseline}).
The partial-chunk adjustment is therefore represented as a \emph{time-based}
signal $c(t)$ (tokens/sec): its time integral is already in tokens and can be
subtracted in exposure space without introducing any step-boundary assumptions.

\paragraph{Implementation note (no pointwise reconstruction required).}
Although we define pressures and corrections as functions of wall-clock time, the
estimators require only integrals over phase windows such as
$\int_{t_{i,s}}^{t_{i,e}} p^{\mathrm{pf}}_{\mathrm{full}}(t)\,dt$ and
$\int_{t_{i,s}}^{t_{i,e}} c(t)\,dt$.
These can be computed exactly by sweeping the trace-induced time grid.


% ============================================================
\subsection{Baseline: Time-Integrated NNLS Estimation}
\label{sec:baseline}

We now present a simple trace-only baseline estimator.
It fits phase durations using time-integrated pressures and reduces coefficient
recovery to a single non-negative least squares (NNLS) regression.

\paragraph{Baseline as fixed step allocation.}
The baseline adopts the latent step-allocation viewpoint in its simplest form:
for each phase instance $i$, it assumes the $N_i$ latent steps are spread
approximately uniformly over the wall-clock interval $[t_{i,s},t_{i,e})$.
Equivalently, it assumes a phase-local constant step density and uses it only to
convert time-integrated pressures (tokens/step $\times$ seconds) into token totals
(tokens) that can serve as regression features.

\begin{algorithm}[t]
\caption{Baseline trace-only estimation}
\label{alg:baseline_intuition}
\begin{algorithmic}[1]
\Require Phase traces $\{(r_i,\tau_i,t_{i,s},t_{i,e},P_{r_i},D_{r_i})\}$, chunk size $C$
\Ensure Estimated execution coefficients $\hat\beta$
\For{each phase instance $i$}
  \State infer step count $N_i$ from trace-visible tokens
  \Comment{definition of $N_i$; §\ref{sec:problem_setup}}
\EndFor
\State construct global time grid from all phase boundaries
\Comment{trace-induced grid for piecewise-constant pressures; §\ref{sec:pressures}}
\For{each time interval in the grid}
  \State measure concurrent prefill and decode activity
  \Comment{instantaneous pressures $p^{\mathrm{pf}}_{\mathrm{full}}(t),p^{\mathrm{dec}}(t)$; §\ref{sec:pressures}}
\EndFor
\For{each prefill request $r$}
  \State apply trace-only partial-chunk correction (optional)
  \Comment{missing mass $\mu_r$ and correction signal $c(t)$; §\ref{sec:prefill_correction}}
\EndFor
\For{each phase instance $i$}
  \State compute phase-level prefill and decode exposures
  \Comment{$A_i^{\mathrm{pf}},A_i^{\mathrm{dec}}$; Eq.~\eqref{eq:baseline_integrated_exposures_pf}--\eqref{eq:baseline_integrated_exposures_dec}}
\EndFor
\State fit execution coefficients via NNLS
\Comment{predictor Eq.~\eqref{eq:baseline_predictor}, objective Eq.~\eqref{eq:baseline_nnls}}
\State \Return $\hat\beta$
\end{algorithmic}
\end{algorithm}

\paragraph{Phase-local step density.}
For phase instance $i$, let $\ell_i=t_{i,e}-t_{i,s}$ be its observed duration and
let $N_i\in\mathbb{N}$ be the trace-inferred step count.
We define the baseline \emph{phase-local step-density proxy} (steps/sec)
\begin{equation}
\widehat\lambda_i \;=\; \frac{N_i}{\ell_i}.
\label{eq:baseline_lambda_hat}
\end{equation}
This proxy is used \emph{only} to convert time integrals into step-aggregated
token exposures in the baseline.\footnote{Implementation detail: to avoid extreme
$\widehat{\lambda}_i$ when $\ell_i$ is very small, we may compute
$\widehat{\lambda}_i = N_i/\max\{\ell_i, \ell_{\min}\}$ for a small
$\ell_{\min}\ge 0$. The default $\ell_{\min}=0$ recovers
Eq.~\eqref{eq:baseline_lambda_hat}.}

\paragraph{Phase-level exposures (baseline regression features).}
Let $p^{\mathrm{pf}}_{\mathrm{full}}(t)$ denote the naive full-chunk prefill
pressure and let $p^{\mathrm{dec}}(t)$ denote the decode pressure, both in units
of tokens/step.
Let $c(t)$ denote a chosen partial-chunk correction signal (tokens/second), e.g.,
$c^{\mathrm{uni}}(t)$ from Eq.~\eqref{eq:uniform_corr_signal_sum},
$c^{\mathrm{end}}(t)$ from Eq.~\eqref{eq:end_corr_signal_sum}, or $c(t)\equiv 0$
(ablation).

We define baseline phase-level exposures (tokens) as
\begin{align}
A^{\mathrm{pf}}_i
&=
\left[ \widehat\lambda_i
\int_{t_{i,s}}^{t_{i,e}} p^{\mathrm{pf}}_{\mathrm{full}}(t)\,dt \right]
\;-\;
\int_{t_{i,s}}^{t_{i,e}} c(t)\,dt,
\label{eq:baseline_integrated_exposures_pf}
\\
A^{\mathrm{dec}}_i
&=
\widehat\lambda_i
\int_{t_{i,s}}^{t_{i,e}} p^{\mathrm{dec}}(t)\,dt.
\label{eq:baseline_integrated_exposures_dec}
\end{align}
The integrals of $p^{\mathrm{pf}}_{\mathrm{full}}(t)$ and $p^{\mathrm{dec}}(t)$ have
units $(\text{tokens}/\text{step})\cdot \text{seconds}$, which are converted into
tokens by $\widehat\lambda_i$ (steps/second), while $\int c(t)\,dt$ is already in
tokens. Accordingly, the correction term is \emph{not} multiplied by
$\widehat\lambda_i$.

\paragraph{Baseline predictor.}
The baseline predicts phase duration as
\begin{equation}
\widehat \ell_i(\beta)
=
\beta_0\,N_i
+
\beta_1\,A^{\mathrm{pf}}_i
+
\beta_2\,A^{\mathrm{dec}}_i,
\label{eq:baseline_predictor}
\end{equation}
where $\beta_0$ has units seconds/step and $\beta_1,\beta_2$ have units
seconds/token, consistent with the step-level model in Eq.~\eqref{eq:step_model}.

\paragraph{NNLS estimation.}
Given a set of phase instances $\mathcal{I}$, we estimate $\beta$ via
non-negative least squares:
\begin{equation}
\min_{\beta \in \mathbb{R}^3_{\ge 0}}
\sum_{i\in\mathcal{I}}
\left(
\widehat \ell_i(\beta) - \ell_i
\right)^2 .
\label{eq:baseline_nnls}
\end{equation}

\paragraph{Bridge to EM.}
The baseline yields a single globally consistent coefficient estimate using only
trace-derived overlap signals.
Its simplifying assumption is the phase-local uniformity implicit in
$\widehat\lambda_i$: the baseline does not attempt to infer how steps are
distributed across the trace-induced grid within a phase, nor can it localize
the final partial prefill chunk in step space.
Section~\ref{sec:em_estimation} removes these limitations by introducing explicit
latent step-allocation variables over the trace grid, using a coefficient-driven
step-density model to compute expected allocations, and incorporating the final
partial prefill chunk exactly at the trace-visible prefill end boundary.
As in the baseline, all computations remain trace-only; the additional structure
is used only to reallocate step exposure within trace-visible phase windows.

% ============================================================
\subsection{EM-Based Trace-Only Estimation with Exact Partial-Chunk Handling}
\label{sec:em_estimation}

We now present a trace-only Expectation--Maximization (EM) formulation of
step-level coefficient estimation.
This formulation leverages a structural property of vLLM-style inference engines:
\emph{all request phase boundaries coincide with global busy-loop step boundaries}.
As a result, each phase consists of an integer number of whole execution steps,
and the final prefill step of a request is known to terminate exactly at the
trace-visible prefill end time.

The EM view provides a clean probabilistic interpretation, simplifies
implementation relative to iterative reweighting schemes, and yields standard
monotonic-improvement guarantees. It is illustrated in Algorithm~\ref{alg:em_simple}.

\begin{algorithm}[t]
\caption{EM trace-only estimation (simplified)}
\label{alg:em_simple}
\begin{algorithmic}[1]
\Require Phase traces, chunk size $C$
\Ensure Estimated execution coefficients $\hat\beta$

\State infer step counts $N_i$ and construct trace-induced time grid
\Comment{trace preprocessing; §\ref{sec:problem_setup}, §\ref{sec:pressures}}

\State compute trace-derived pressures $p^{\mathrm{pf}}_{\mathrm{full},j},\,p^{\mathrm{dec}}_j$
\Comment{overlap-based pressures; §\ref{sec:pressures}}

\State initialize coefficients $\beta^{(0)}$ using baseline NNLS with no correction
\Comment{initializer; §\ref{sec:baseline}}

\For{$m=1,2,\dots$ until convergence}

  \State estimate local step density from $\beta^{(m-1)}$
  \Comment{cell-level step-rate model; Eq.~\eqref{eq:em_step_rate}}

  \State allocate expected steps of each phase over the grid
  \Comment{latent step allocation; Eq.~\eqref{eq:em_pi}}

  \State localize the final prefill step and apply exact partial-chunk correction
  \Comment{step-space correction; §\ref{sec:em_estimation}}

  \State refit coefficients by NNLS using expected step-averaged pressures
  \Comment{M-step regression; Eq.~\eqref{eq:em_mstep}}

\EndFor

\State \Return $\hat\beta \gets \beta^{(m)}$
\end{algorithmic}
\end{algorithm}


We begin by defining the trace-induced grid and latent step-allocation variables,
then describe initialization and EM iteration.


% ------------------------------------------------------------
\subsubsection{Trace Grid and Latent Step Allocation}

Let $\{[g_j,g_{j+1})\}_{j=1}^J$ denote the trace-induced time grid formed by the
union of all phase boundaries.
Under the alignment assumption above, each grid boundary coincides with a global
step boundary, and each grid cell contains an integer number of whole execution
steps.

For each phase instance $i$ with window $[t_{i,s},t_{i,e})$ and trace-inferred
step count $N_i$, define
\[
\mathcal{J}(i)
=
\bigl\{ j : [g_j,g_{j+1}) \subseteq [t_{i,s},t_{i,e}) \bigr\}.
\]

We introduce latent step-allocation variables
\[
Z_{ij} \in \{0,1,2,\dots\},
\qquad
\sum_{j\in\mathcal{J}(i)} Z_{ij} = N_i,
\]
where $Z_{ij}$ denotes the (unobserved) number of busy-loop steps of phase $i$
executed within grid cell $j$.

These variables represent uncertainty about how steps are distributed across
time intervals, even though their total count is known from the trace.

% ------------------------------------------------------------
\subsubsection{Exact Localization of the Final Prefill Step}

For a request $r$ in its prefill phase, execution proceeds for $N_r$ steps,
of which exactly one—the final step—processes a partial chunk.
Let $\mu_r = C-\rho_r$ denote the missing token mass of that final step.

Because prefill completion occurs at a trace-visible phase boundary, the final
prefill step of request $r$ is known to lie in the unique grid cell
\[
j^\star(r)
\quad\text{such that}\quad
g_{j^\star(r)+1} = t_{r,e}.
\]

We therefore treat the final prefill step as deterministically localized within
cell $j^\star(r)$.
No probabilistic modeling is required for its position.

To enforce this constraint, we decompose the latent allocation for the prefill
phase of request $r$ as follows:
\[
Z_{rj^\star(r)} = 1 + Z'_{rj^\star(r)}, \qquad
\sum_{j\in\mathcal{J}(r)} Z'_{rj} = N_r - 1,
\]
where the remaining $N_r-1$ steps are allocated across grid cells according to
the EM step-allocation model described below.

% ------------------------------------------------------------
\subsubsection{Step-Rate Model}

At EM iteration $m$, the current coefficient vector $\beta^{(m-1)}$ defines a
cell-level step-time proxy.
Let $p^{\mathrm{dec}}_j$ and $p^{\mathrm{pf}}_{\mathrm{full},j}$ denote the raw
decode and full-chunk prefill pressures on grid cell $j$.
Define
\begin{equation}
\Delta^{(m)}_j
=
\beta^{(m-1)}_0
+
\beta^{(m-1)}_1\,\tilde p^{\mathrm{pf},(m-1)}_j
+
\beta^{(m-1)}_2\,p^{\mathrm{dec}}_j,
\qquad
\lambda^{(m)}_j = \frac{1}{\Delta^{(m)}_j},
\label{eq:em_step_rate}
\end{equation}
where $\tilde p^{\mathrm{pf},(m-1)}_j$ is the effective prefill pressure carried
over from the previous iteration.
The quantity $\lambda^{(m)}_j$ serves as a trace-only proxy for the local step
density (steps per second) on grid cell $j$.

\paragraph{Decode pressure and iteration dependence.}
We emphasize that decode pressure $p^{\mathrm{dec}}_j$ is fully trace-derived and
does not depend on the iteration index.
Iteration dependence in decode-related quantities arises only through the
step-allocation weights induced by the current step-density model
$\lambda^{(m)}$, not through any modification of the decode pressure itself.

% ------------------------------------------------------------
\subsubsection{Initialization and First EM Iteration}
\label{sec:em_initialization}

The EM algorithm is initialized using the baseline trace-only estimator
(Section~\ref{sec:baseline}), which provides a consistent starting point for the
step-level execution coefficients without requiring step-aware modeling.

\paragraph{Baseline initialization.}
Let $\beta^{(0)}=(\beta^{(0)}_0,\beta^{(0)}_1,\beta^{(0)}_2)$ denote the coefficient
vector obtained from the baseline NNLS fit.
At initialization, we define the effective prefill pressure on each trace-grid
cell to be the naive full-chunk pressure:
\begin{equation}
\tilde p^{\mathrm{pf},(0)}_j
\;:=\;
p^{\mathrm{pf}}_{\mathrm{full},j}.
\label{eq:em_init_prefill_pressure}
\end{equation}
The trace-derived decode pressure $p^{\mathrm{dec}}_j$ is retained unchanged.

No partial-chunk correction is applied at initialization.
This ensures that the baseline estimator is used \emph{only} to initialize the
coefficient vector and does not introduce step-level assumptions.

\paragraph{Step-density model for the first iteration.}
Using $\beta^{(0)}$ and the initialized pressures, the cell-level step-time model
for the first EM iteration is
\begin{equation}
\Delta^{(1)}_j
=
\beta^{(0)}_0
+
\beta^{(0)}_1\,p^{\mathrm{pf}}_{\mathrm{full},j}
+
\beta^{(0)}_2\,p^{\mathrm{dec}}_j,
\qquad
\lambda^{(1)}_j = \frac{1}{\Delta^{(1)}_j}.
\label{eq:em_first_step_density}
\end{equation}

\paragraph{Role of the first iteration.}
The first EM iteration is the point at which step-aware modeling is introduced.
Using $\lambda^{(1)}_j$, expected step allocations are computed, and partial-chunk
effects are incorporated explicitly for the first time, producing updated
effective pressures $\tilde p^{\mathrm{pf},(1)}_j$ and coefficients
$\beta^{(1)}$.

% ------------------------------------------------------------
\subsubsection{E-Step: Expected Step Allocation}

Conditioned on $N_i$ and $\beta^{(m-1)}$, we assume that the $N_i$ steps of phase
$i$ are allocated across grid cells proportionally to step density:
\begin{equation}
(Z'_{ij})_{j\in\mathcal{J}(i)}
\;\big|\;
\beta^{(m-1)}
\sim
\mathrm{Multinomial}\!\left(
N_i - \mathbf{1}\{\tau_i=\textsf{prefill}\};
(\pi^{(m)}_{ij})_{j\in\mathcal{J}(i)}
\right),
\label{eq:em_multinomial}
\end{equation}
where
\begin{equation}
\pi^{(m)}_{ij}
=
\frac{\lambda^{(m)}_j}
{\sum_{u\in\mathcal{J}(i)} \lambda^{(m)}_u}.
\label{eq:em_pi}
\end{equation}

The expected step counts are therefore
\[
\mathbb{E}[Z_{ij}]
=
\begin{cases}
1 + (N_i-1)\pi^{(m)}_{ij}, & \text{if $i$ is prefill and $j=j^\star(r_i)$}, \\
(N_i-1)\pi^{(m)}_{ij}, & \text{if $i$ is prefill and $j\neq j^\star(r_i)$}, \\
N_i\,\pi^{(m)}_{ij}, & \text{if $i$ is decode}.
\end{cases}
\]

\paragraph{Expected step-averaged pressures.}
Since pressures are constant within each grid cell, the expected step-averaged
pressures for phase $i$ are
\begin{align}
\bar p^{\mathrm{dec},(m)}_i
&=
\sum_{j\in\mathcal{J}(i)} \pi^{(m)}_{ij}\, p^{\mathrm{dec}}_j,
\\
\bar p^{\mathrm{pf},(m)}_i
&=
\sum_{j\in\mathcal{J}(i)} \pi^{(m)}_{ij}\, \tilde p^{\mathrm{pf},(m)}_j.
\end{align}

% ------------------------------------------------------------
\subsubsection{Partial-Chunk Correction}

The missing token mass $\mu_r$ is subtracted exactly once in the final prefill
cell $j^\star(r)$.
Specifically, the effective prefill pressure is updated as
\begin{equation}
\tilde p^{\mathrm{pf},(m)}_{j^\star(r)}
=
p^{\mathrm{pf}}_{\mathrm{full},j^\star(r)}
-
\frac{\mu_r}{\mathbb{E}[Z_{rj^\star(r)}]},
\label{eq:em_partial_chunk}
\end{equation}
while $\tilde p^{\mathrm{pf},(m)}_j = p^{\mathrm{pf}}_{\mathrm{full},j}$ for all
other cells.
This adjustment preserves units (tokens/step) and ensures that exactly one
partial chunk per request is accounted for in expectation.

% ------------------------------------------------------------
\subsubsection{M-Step: Coefficient Update}

With the expected step-averaged pressures fixed, we update $\beta$ by solving
\begin{equation}
\beta^{(m)}
=
\arg\min_{\beta\ge 0}
\sum_{i\in\mathcal{I}}
\left(
N_i\beta_0
+
[N_i\bar p^{\mathrm{pf},(m)}_i]\beta_1
+
[N_i\bar p^{\mathrm{dec},(m)}_i]\beta_2
-
\ell_i
\right)^2.
\label{eq:em_mstep}
\end{equation}

Iterations continue until convergence.

\paragraph{Summary.}
The EM algorithm alternates between (i) estimating how execution steps are
distributed across time using a step-density proxy, while exactly localizing the
final partial prefill step, and (ii) refitting step-level execution coefficients.
All computations are trace-only and require no reconstruction of individual step
boundaries.

% ============================================================
\subsection{Theoretical Properties}
\label{sec:em_theory}

\begin{theorem}[Monotonic Improvement and Convergence]
\label{thm:em_convergence}
Let $\{\beta^{(m)}\}_{m\ge 0}$ be the sequence produced by the EM algorithm in
Section~\ref{sec:em_estimation}.
Then the observed-data squared-error objective
\[
\mathcal{L}(\beta)
=
\sum_{i\in\mathcal{I}}
\left(
\widehat\ell_i(\beta) - \ell_i
\right)^2
\]
is non-increasing across iterations.
Moreover, every accumulation point of $\{\beta^{(m)}\}$ is a stationary point of
the constrained least-squares problem.
\end{theorem}

\begin{proof}
The EM algorithm constructs, at each iteration $m$, a surrogate objective given by
the conditional expectation of the complete-data squared-error loss with respect
to the posterior distribution of the latent step-allocation variables
$\{Z_{ij}\}$ under $\beta^{(m-1)}$.

In the E-step, these expectations are computed exactly, incorporating the known
localization of the final prefill step.
In the M-step, the surrogate objective is minimized over $\beta\ge 0$, yielding a
convex non-negative least squares problem.

By standard EM convergence theory, each iteration does not increase the
observed-data objective, and any accumulation point of the iterates is a
stationary point of the constrained problem.
See \cite{dempster1977em,wu1983convergence} for general results.
\end{proof}

\appendix
\section{Deterministic Step-Density Reweighting (MM View)}
\paragraph{Why reweighting helps.}
This estimator remains wall-clock--weighted because the baseline exposures 
$A_i^{\mathrm{pf}}$ and $A_i^{\mathrm{dec}}$ are formed
by integrating instantaneous pressures over wall-clock time 
within each phase,
using the phase-average step density proxy $\widehat\lambda_i$ rather than a
time-varying step density.
As a result, phases that coincide with long-step periods can exert
disproportionate influence, motivating the step-density--reweighted estimator
in Section~\ref{sec:step_density}.


% ============================================================
\subsection{Step-Density Reweighted Estimation}
\label{sec:step_density}

We now introduce an iterative estimator that shifts fitting from wall-clock
weighting toward step-level weighting. The step-density reweighted estimator can be combined with any of the
trace-only prefill correction schemes from
Section~\ref{sec:prefill_correction}.
In addition, it enables a $\beta$-informed refinement that localizes the
prefill partial chunk using the inferred step-density model.

\begin{algorithm}[t]
\caption{Iterative step-density reweighted estimation}
\label{alg:iterative_intuition}
\begin{algorithmic}[1]
\Require Phase traces, chunk size $C$, initial coefficients $\beta^{(0)}$, tolerance $\epsilon$
\Ensure Refined execution coefficients $\beta^\star$

\State initialize $\beta^{(0)} \gets$ baseline NNLS estimate
\Comment{§\ref{sec:baseline}, Eq.~\eqref{eq:baseline_nnls}}

\For{$m=1,2,\dots$}
  \State compute $\Delta^{(m)}(t)$ and $\lambda^{(m)}(t)$ from $\beta^{(m-1)}$
  \Comment{\emph{instantaneous} step-time and step-density on the trace grid; §\ref{sec:local_step_density}, Eq.~\eqref{eq:local_step_time_m}, Eq.~\eqref{eq:step_density_m}}

  \State assign step exposure across time intervals
  \Comment{compute phase/request attribution densities $q_i^{(m)},q_r^{(m)}$ from $\lambda^{(m)}$ on the trace grid; §\ref{sec:local_step_density}}

  \For{each prefill request $r$}
    \State localize final partial chunk using step density
    \Comment{$\beta$-informed placement of missing prefill tokens within the prefill window via request-level attribution and last-step window; §\ref{sec:beta_informed_prefill_correction}, Eq.~\eqref{eq:qr_def_m}--Eq.~\eqref{eq:last_step_window_m}}
  \EndFor

  \For{each phase instance $i$}
    \State compute step-averaged prefill and decode pressures
    \Comment{step-averaged (i.e., step-weighted) pressures from \emph{instantaneous} pressures and phase-level attribution; §\ref{sec:step_averaged_pressures}, Eq.~\eqref{eq:step_averaged_pressures_m}}
  \EndFor

  \State refit $\beta^{(m)}$ using frozen iteration-$m$ features
  \Comment{NNLS on step-weighted exposures $N_i\bar p_i^{\mathrm{pf}}$ and $N_i\bar p_i^{\mathrm{dec}}$ (tokens), holding attribution fixed; §\ref{sec:step_density}, Eq.~\eqref{eq:sr_nnls_m}}

  \If{$\|\beta^{(m)}-\beta^{(m-1)}\|_2 < \epsilon$} 
    \State \textbf{break}
  \EndIf
\EndFor

\State set $\beta^\star \gets \beta^{(m)}$
\State \Return $\beta^\star$

\end{algorithmic}
\end{algorithm}

\paragraph{Iteration semantics.}
At the start of iteration $m$, the coefficient vector $\beta^{(m-1)}$ and all
features computed in iteration $m-1$ are available.
All quantities carrying superscript $m$ are computed \emph{during} iteration
$m$ using $\beta^{(m-1)}$ and previously computed features, and are held fixed
while solving for $\beta^{(m)}$.

\paragraph{Update map interpretation.}
The iterative estimator can be viewed as the repeated application of a
deterministic update map.
Specifically, given the previous iterate and lagged effective prefill pressure,
the algorithm applies
\[
(\beta^{(m-1)},\tilde p^{\mathrm{pf},(m-1)})
\;\xmapsto{\;\mathcal{T}\;}
(\beta^{(m)},\tilde p^{\mathrm{pf},(m)}),
\]
where the update map $\mathcal{T}$ is realized through the following
trace-only construction chain:
\begin{align*}
& \beta^{(m-1)}
\;\mapsto\;
\Delta^{(m)}(t)
\;\mapsto\;
\lambda^{(m)}(t)
\;\mapsto\; 
\bigl(q_i^{(m)}(t), q_r^{(m)}(t), F_r^{(m)}(t), \mathcal{W}_r^{(m)}\bigr)
\;\mapsto\; \\
& \bigl(c_r^{(m)}(t), c^{(m)}(t), \tilde p^{\mathrm{pf},(m)}(t)\bigr)
\;\mapsto\;
\bigl(\bar p_i^{\mathrm{pf},(m)}, \bar p_i^{\mathrm{dec},(m)}\bigr)
\;\mapsto\;
\beta^{(m)}.
\end{align*}
All quantities with superscript $(m)$ are computed during iteration $m$ from
$\beta^{(m-1)}$ and trace-derived signals, then held fixed while solving the
NNLS subproblem for $\beta^{(m)}$.


\subsubsection{Local Step-Time Model and Step Density (Iteration-Indexed)}
\label{sec:local_step_density}

The iterative estimator proceeds in outer iterations indexed by $m$.
At the start of iteration $m$, we treat the current coefficient vector $\beta^{(m-1)}$
as fixed and construct a trace-only step-density proxy on the trace-induced
time grid. All attribution quantities computed from this proxy (e.g.,
$q_i^{(m)}$, $q_r^{(m)}$, $\mathcal{W}_r^{(m)}$, $c^{(m)}$, and
$\bar p_i^{(\cdot),(m)}$) are then held fixed while solving for $\beta^{(m)}$
via an NNLS subproblem.

Given instantaneous pressures and the effective prefill pressure $\tilde p^{\mathrm{pf},(m-1)}(t)$
computed in the previous iteration (and held fixed), define the iteration-$m$
local step-time model as
\begin{equation}
\Delta^{(m)}(t)
=
\beta^{(m-1)}_0
+
\beta^{(m-1)}_1\,\tilde p^{\mathrm{pf},(m-1)}(t)
+
\beta^{(m-1)}_2\,p^{\mathrm{dec}}(t),
\qquad \Delta^{(m)}(t) > 0.
\label{eq:local_step_time_m}
\end{equation}

The induced \emph{step density} (steps/sec) is
\begin{equation}
\lambda^{(m)}(t) = \frac{1}{\Delta^{(m)}(t)}.
\label{eq:step_density_m}
\end{equation}

% ============================================================
\subsubsection{$\beta$-Informed Partial-Chunk Correction (Iteration-Indexed)}
\label{sec:beta_informed_prefill_correction}

Using $\lambda^{(m)}(t)$ from Eq.~\eqref{eq:step_density_m}, define the
normalized step-time attribution density over request $r$'s prefill window:
\begin{equation}
q_r^{(m)}(t)
=
\frac{\lambda^{(m)}(t)}{\int_{t_{r,s}}^{t_{r,e}} \lambda^{(m)}(u)\,du},
\qquad
\int_{t_{r,s}}^{t_{r,e}} q_r^{(m)}(t)\,dt = 1.
\label{eq:qr_def_m}
\end{equation}

Define the corresponding CDF
\begin{equation}
F_r^{(m)}(t)=\int_{t_{r,s}}^{t} q_r^{(m)}(u)\,du,
\label{eq:Fr_def_m}
\end{equation}
and the last-step window as
\begin{equation}
\mathcal{W}_r^{(m)}
=
\Bigl\{
t\in[t_{r,s},t_{r,e})
:
F_r^{(m)}(t)\ge 1-\tfrac{1}{N_r}
\Bigr\}.
\label{eq:last_step_window_m}
\end{equation}

The per-request correction signal (tokens/sec) is
\begin{equation}
c_r^{(m)}(t)
=
\mu_r\,
\frac{q_r^{(m)}(t)\,\mathbf{1}\{t\in\mathcal{W}_r^{(m)}\}}
{\int_{\mathcal{W}_r^{(m)}} q_r^{(m)}(u)\,du},
\label{eq:cr_beta_informed_m}
\end{equation}
with aggregate correction $c^{(m)}(t)=\sum_r c_r^{(m)}(t)$.

The effective prefill pressure is
\begin{equation}
\tilde p^{\mathrm{pf},(m)}(t)
=
p^{\mathrm{pf}}_{\mathrm{full}}(t)
-
\frac{c^{(m)}(t)}{\lambda^{(m)}(t)}.
\label{eq:prefill_pressure_beta_informed_m}
\end{equation}

Since $c^{(m)}(t)/\lambda^{(m)}(t)$ has units
$(\text{tokens}/\text{second})/(\text{steps}/\text{second})=\text{tokens}/\text{step}$,
$\tilde p^{\mathrm{pf},(m)}(t)$ remains a tokens/step pressure.

We note that all instantaneous quantities above enter only through integrals over the trace-induced grid
$\{[g_j,g_{j+1})\}$, on which pressures (and hence $\lambda^{(m)}$) are piecewise-constant.

\subsubsection{Normalized Step Density within a Phase (Iteration-Indexed)}

For phase instance $i$, define the iteration-$(m)$ phase mass
\[
\Lambda_i^{(m)}
=
\int_{t_{i,s}}^{t_{i,e}} \lambda^{(m)}(t)\,dt,
\qquad
q_i^{(m)}(t)
=
\frac{\lambda^{(m)}(t)}{\Lambda_i^{(m)}}.
\]
By construction, $\int_{t_{i,s}}^{t_{i,e}} q_i^{(m)}(t)\,dt = 1$.
All phase-level attribution quantities are computed during iteration $m$
and held fixed while solving for $\beta^{(m)}$.

\subsubsection{Step-Weighted Exposures}
\label{sec:step_averaged_pressures}

\begin{equation}
\bar p^{\mathrm{pf},(m)}_i
=
\int_{t_{i,s}}^{t_{i,e}} \tilde p^{\mathrm{pf},(m)}(t)\, q_i^{(m)}(t)\,dt,
\qquad
\bar p^{\mathrm{dec},(m)}_i
=
\int_{t_{i,s}}^{t_{i,e}} p^{\mathrm{dec}}(t)\, q_i^{(m)}(t)\,dt.
\label{eq:step_averaged_pressures_m}
\end{equation}

\paragraph{From step-averaged pressure to exposure.}
The quantities $\bar p_i^{\mathrm{pf},(m)}$ and $\bar p_i^{\mathrm{dec},(m)}$
are \emph{step-averaged pressures} (tokens/step), obtained by averaging
instantaneous pressures with respect to the iteration-$m$ step-time attribution
$q_i^{(m)}(t)$.
The corresponding \emph{step-weighted exposures} used in the NNLS subproblem are
$N_i\bar p_i^{\mathrm{pf},(m)}$ and $N_i\bar p_i^{\mathrm{dec},(m)}$ (tokens).

In the special case where $\lambda^{(m)}(t)$ is approximately constant over
$[t_{i,s},t_{i,e})$, the step-time attribution is approximately uniform and the
resulting step-weighted exposures reduce to the baseline construction (up to
numerical integration error).

\paragraph{Units and interpretation.}
$\bar p_i^{\mathrm{pf},(m)}$ and $\bar p_i^{\mathrm{dec},(m)}$ have units of tokens/step,
so $N_i\bar p_i^{\mathrm{pf},(m)}$ and $N_i\bar p_i^{\mathrm{dec},(m)}$ are step-aggregated
token exposures (tokens) for phase $i$ under the iteration-$m$ attribution induced by
$\lambda^{(m)}(t)$.
If $\lambda^{(m)}(t)$ is approximately constant over $[t_{i,s},t_{i,e})$, then
$q_i^{(m)}(t)$ is approximately uniform and these step-weighted exposures reduce to the
baseline construction (up to numerical integration error and any chosen prefill correction).

\subsubsection{MM-Style Iterative NNLS}

\begin{equation}
\beta^{(m)}
=
\arg\min_{\beta\ge 0}
\sum_{i\in\mathcal{I}}
\left(
N_i\beta_0
+
\bigl[N_i\bar p^{\mathrm{pf},(m)}_i\bigr]\beta_1
+
\bigl[N_i\bar p^{\mathrm{dec},(m)}_i\bigr]\beta_2
-
\ell_i
\right)^2 .
\label{eq:sr_nnls_m}
\end{equation}

where $\bar p^{\mathrm{pf},(m)}_i$ and $\bar p^{\mathrm{dec},(m)}_i$ are computed 
via Eqs.~\eqref{eq:local_step_time_m}--\eqref{eq:prefill_pressure_beta_informed_m} and \eqref{eq:step_averaged_pressures_m}
and are held fixed while optimizing over $\beta$.

Optional damping
$\beta^{(m)} \leftarrow (1-\eta)\beta^{(m-1)} + \eta\beta^{(m)}$
improves numerical stability. We iterate until 
$\|\beta^{(m)} - \beta^{(m-1)}\|_2 < \epsilon$ or a maximum
iteration count is reached. 

\paragraph{Robust loss and fixed-point view.}
To mitigate outliers, we optionally replace the squared loss in
Eq.~\eqref{eq:sr_nnls_m} with a Huber loss $\rho_\delta$ applied to each residual.

% ============================================================
\subsection{Limitations and Scope}
\label{sec:limitations}

This approach assumes a single sequential busy-loop and accurate knowledge of
engine scheduling rules.
Partial-chunk corrections remain approximate due to unobserved step
boundaries.
Identifiability requires sufficient variation in token pressures.
Despite these limitations, the method provides a practical and non-intrusive
path to step-level calibration using only production traces.

\paragraph{Simulator linkage.}
The estimated coefficients $\beta^\star$ are used directly in the step-time
model (Eq.~\eqref{eq:step_model}) of the discrete-event simulator.

\label{app:mm}


\bibliographystyle{plain}
\bibliography{blis}

\end{document}
